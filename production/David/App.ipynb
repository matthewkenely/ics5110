{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aim is to create a model that can predict the final grade (G3) from the rest of the dataset. \n",
    "# ie. G3 is the target label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports & Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"G3\"\n",
    "ONE_BOUND = 0; ZERO_BOUND = 0\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Dataset and Correlation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugeseDF = pd.read_csv('../data/Portuguese.csv')\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in portugeseDF.select_dtypes(include=['object']).columns:\n",
    "    portugeseDF[col] = le.fit_transform(portugeseDF[col])\n",
    "    \n",
    "correlation_matrix = portugeseDF.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool), k=1)\n",
    "correlation_matrix = correlation_matrix.mask(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Different Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegressionModel = LogisticRegression(max_iter=10000)\n",
    "SVCModel = SVC(kernel='rbf') \n",
    "randomForestModel = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "gradientBoostingModel = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "modelsDictionary = {\"Logistic Regression\": logisticRegressionModel, \"Support Vector Machine\":SVCModel, \"Random Forest\": randomForestModel, \"Gradient Boosting\": gradientBoostingModel}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Functions to Create New Dataset and Run the Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makingNewDataset(correlationMatrix, dataframe):\n",
    "    orignalAttributes = dict(correlationMatrix.loc[TARGET])\n",
    "    newAttributes = list()\n",
    "\n",
    "    for key in orignalAttributes:\n",
    "        if orignalAttributes[key] > ONE_BOUND or orignalAttributes[key] < -(ONE_BOUND): pass\n",
    "        elif orignalAttributes[key] < ZERO_BOUND and orignalAttributes[key] > -(ZERO_BOUND): pass\n",
    "        else: newAttributes.append(key)\n",
    "    newAttributes.append(TARGET)\n",
    "\n",
    "    newData = {}\n",
    "    for attribute in newAttributes:\n",
    "        newData[attribute] = dataframe[attribute]\n",
    "    newPortugeseDF = pd.DataFrame(newData)\n",
    "    return newPortugeseDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTheModel (dataframe, modelName, modelToRun):\n",
    "    features = dataframe.drop(columns=[TARGET]); target = dataframe[TARGET]\n",
    "    featureTrain, featureTest, targetTrain, targetTest = train_test_split(features, target, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "    modelToRun.fit(featureTrain, targetTrain)\n",
    "\n",
    "    testPredictions = modelToRun.predict(featureTest)\n",
    "    accuracy = accuracy_score(targetTest, testPredictions)\n",
    "    if modelName == \"Support Vector Machine\":\n",
    "        print(f\"{modelName} Accuracy: \\t{accuracy * 100:.3f}%\")\n",
    "    else:\n",
    "        print(f\"{modelName} Accuracy: \\t\\t{accuracy * 100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test Section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - When correlation values in range: 0.8 to 0.1 and -0.1 to -0.8 - - \n",
      "Number of Removed Columns: 16\n",
      "Logistic Regression Accuracy: \t\t16.923%\n",
      "Support Vector Machine Accuracy: \t21.538%\n",
      "Random Forest Accuracy: \t\t12.308%\n",
      "Gradient Boosting Accuracy: \t\t14.615%\n",
      "\n",
      "- - When correlation values in range: 0.8 to 0.05 and -0.05 to -0.8 - - \n",
      "Number of Removed Columns: 5\n",
      "Logistic Regression Accuracy: \t\t17.692%\n",
      "Support Vector Machine Accuracy: \t18.462%\n",
      "Random Forest Accuracy: \t\t16.923%\n",
      "Gradient Boosting Accuracy: \t\t16.923%\n",
      "\n",
      "- - When correlation values in range: 0.8 to 0.06 and -0.06 to -0.8 - - \n",
      "Number of Removed Columns: 9\n",
      "Logistic Regression Accuracy: \t\t14.615%\n",
      "Support Vector Machine Accuracy: \t19.231%\n",
      "Random Forest Accuracy: \t\t19.231%\n",
      "Gradient Boosting Accuracy: \t\t17.692%\n",
      "\n",
      "- - When correlation values in range: 0.8 to 0.07 and -0.07 to -0.8 - - \n",
      "Number of Removed Columns: 11\n",
      "Logistic Regression Accuracy: \t\t16.923%\n",
      "Support Vector Machine Accuracy: \t17.692%\n",
      "Random Forest Accuracy: \t\t15.385%\n",
      "Gradient Boosting Accuracy: \t\t16.923%\n",
      "\n",
      "- - When correlation values in range: 0.8 to 0.08 and -0.08 to -0.8 - - \n",
      "Number of Removed Columns: 12\n",
      "Logistic Regression Accuracy: \t\t18.462%\n",
      "Support Vector Machine Accuracy: \t16.923%\n",
      "Random Forest Accuracy: \t\t15.385%\n",
      "Gradient Boosting Accuracy: \t\t20.769%\n",
      "\n",
      "- - When correlation values in range: 0.8 to 0.09 and -0.09 to -0.8 - - \n",
      "Number of Removed Columns: 13\n",
      "Logistic Regression Accuracy: \t\t16.154%\n",
      "Support Vector Machine Accuracy: \t19.231%\n",
      "Random Forest Accuracy: \t\t15.385%\n",
      "Gradient Boosting Accuracy: \t\t18.462%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Different Tests to decide on best hyper parameters\n",
    "\n",
    "# Test 1\n",
    "ONE_BOUND =0.8\n",
    "ZERO_BOUND = 0.1\n",
    "print(f\"- - When correlation values in range: {ONE_BOUND} to {ZERO_BOUND} and -{ZERO_BOUND} to -{ONE_BOUND} - - \")\n",
    "\n",
    "newDataset = makingNewDataset(correlation_matrix, portugeseDF)\n",
    "print(f\"Number of Removed Columns: {len(list(portugeseDF.keys()) )-  len(list(newDataset.keys()))}\")\n",
    "for modelName in modelsDictionary:\n",
    "    runTheModel(newDataset, modelName, modelsDictionary[modelName])\n",
    "print()\n",
    "\n",
    "# Test 2\n",
    "ONE_BOUND =0.8\n",
    "ZERO_BOUND = 0.05\n",
    "print(f\"- - When correlation values in range: {ONE_BOUND} to {ZERO_BOUND} and -{ZERO_BOUND} to -{ONE_BOUND} - - \")\n",
    "\n",
    "newDataset = makingNewDataset(correlation_matrix, portugeseDF)\n",
    "print(f\"Number of Removed Columns: {len(list(portugeseDF.keys()) )-  len(list(newDataset.keys()))}\")\n",
    "for modelName in modelsDictionary:\n",
    "    runTheModel(newDataset, modelName, modelsDictionary[modelName])\n",
    "print()\n",
    "\n",
    "# Test 3\n",
    "ONE_BOUND =0.8\n",
    "ZERO_BOUND = 0.06\n",
    "print(f\"- - When correlation values in range: {ONE_BOUND} to {ZERO_BOUND} and -{ZERO_BOUND} to -{ONE_BOUND} - - \")\n",
    "\n",
    "newDataset = makingNewDataset(correlation_matrix, portugeseDF)\n",
    "print(f\"Number of Removed Columns: {len(list(portugeseDF.keys()) )-  len(list(newDataset.keys()))}\")\n",
    "for modelName in modelsDictionary:\n",
    "    runTheModel(newDataset, modelName, modelsDictionary[modelName])\n",
    "print()\n",
    "\n",
    "# Test 4\n",
    "ONE_BOUND =0.8\n",
    "ZERO_BOUND = 0.07\n",
    "print(f\"- - When correlation values in range: {ONE_BOUND} to {ZERO_BOUND} and -{ZERO_BOUND} to -{ONE_BOUND} - - \")\n",
    "\n",
    "newDataset = makingNewDataset(correlation_matrix, portugeseDF)\n",
    "print(f\"Number of Removed Columns: {len(list(portugeseDF.keys()) )-  len(list(newDataset.keys()))}\")\n",
    "for modelName in modelsDictionary:\n",
    "    runTheModel(newDataset, modelName, modelsDictionary[modelName])\n",
    "print()\n",
    "\n",
    "# Test 5\n",
    "ONE_BOUND =0.8\n",
    "ZERO_BOUND = 0.08\n",
    "print(f\"- - When correlation values in range: {ONE_BOUND} to {ZERO_BOUND} and -{ZERO_BOUND} to -{ONE_BOUND} - - \")\n",
    "\n",
    "newDataset = makingNewDataset(correlation_matrix, portugeseDF)\n",
    "print(f\"Number of Removed Columns: {len(list(portugeseDF.keys()) )-  len(list(newDataset.keys()))}\")\n",
    "for modelName in modelsDictionary:\n",
    "    runTheModel(newDataset, modelName, modelsDictionary[modelName])\n",
    "print()\n",
    "\n",
    "# Test 6\n",
    "ONE_BOUND =0.8\n",
    "ZERO_BOUND = 0.09\n",
    "print(f\"- - When correlation values in range: {ONE_BOUND} to {ZERO_BOUND} and -{ZERO_BOUND} to -{ONE_BOUND} - - \")\n",
    "\n",
    "newDataset = makingNewDataset(correlation_matrix, portugeseDF)\n",
    "print(f\"Number of Removed Columns: {len(list(portugeseDF.keys()) )-  len(list(newDataset.keys()))}\")\n",
    "for modelName in modelsDictionary:\n",
    "    runTheModel(newDataset, modelName, modelsDictionary[modelName])\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AppliedMachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
