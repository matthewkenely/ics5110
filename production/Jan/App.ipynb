{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"failures\" # the target variable\n",
    "\n",
    "# ONE_BOUND is the bounding area from the extremes (ie. 1 and -1), to remove the models that are too correlated with the target\n",
    "# ZERO_BOUND is the bounding area from the middle (ie. 0), to remove the models that are too uncorrelated with the target\n",
    "ONE_BOUND = 0.5 ; ZERO_BOUND = 0.065 \n",
    "ONE_BOUND = 1 ; ZERO_BOUND = 0\n",
    "\n",
    "\n",
    "TEST_SIZE = 0.2 # percentage of the dataset to be used as a test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Frame and Correlation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugeseDF = pd.read_csv('../data/Portuguese.csv')\n",
    "\n",
    "# This part is copied from \"Dataset.ipynb\" to get the confusion matrix\n",
    "le = LabelEncoder()\n",
    "for col in portugeseDF.select_dtypes(include=['object']).columns:\n",
    "    portugeseDF[col] = le.fit_transform(portugeseDF[col])\n",
    "    \n",
    "correlation_matrix = portugeseDF.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool), k=1)\n",
    "correlation_matrix = correlation_matrix.mask(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **New Dataset Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makingNewDataset(correlationMatrix, dataframe):\n",
    "    orignalAttributesRow = dict(correlationMatrix.loc[TARGET])\n",
    "    orignalAttributesColumn = dict(correlationMatrix[TARGET])\n",
    "\n",
    "    # print(orignalAttributesRow)\n",
    "    # print(orignalAttributesColumn)\n",
    "\n",
    "    newAttributes = list()\n",
    "    removedAttributes = list()\n",
    "\n",
    "    #True = Vertical, False = Horizontal\n",
    "    Lineflag = False\n",
    "\n",
    "    # iterate through features to choose which to keep\n",
    "    for key in orignalAttributesRow:\n",
    "        if key == TARGET:\n",
    "            Lineflag = True\n",
    "            newAttributes.append(key) # add target to new dataframe \n",
    "       \n",
    "        #Horizontal Correlation\n",
    "        if Lineflag == False:\n",
    "            if orignalAttributesRow[key] > ONE_BOUND or orignalAttributesRow[key] < -(ONE_BOUND): removedAttributes.append(key) # high correlation\n",
    "            elif orignalAttributesRow[key] < ZERO_BOUND and orignalAttributesRow[key] > -(ZERO_BOUND): removedAttributes.append(key) # low correlation\n",
    "            else: newAttributes.append(key) # add featuers that are in the acceptable range to new dataframe\n",
    "\n",
    "        #Vertical Correlation\n",
    "        if Lineflag == True:\n",
    "            if orignalAttributesColumn[key] > ONE_BOUND or orignalAttributesColumn[key] < -(ONE_BOUND): removedAttributes.append(key) # high correlation\n",
    "            elif orignalAttributesColumn[key] < ZERO_BOUND and orignalAttributesColumn[key] > -(ZERO_BOUND): removedAttributes.append(key) # low correlation\n",
    "            else: newAttributes.append(key) # add featuers that are in the acceptable range to new dataframe\n",
    "    \n",
    "    # make new dataframe\n",
    "    newData = {}\n",
    "    for attribute in newAttributes:\n",
    "        newData[attribute] = dataframe[attribute]\n",
    "    newPortugeseDF = pd.DataFrame(newData)\n",
    "\n",
    "    return [newPortugeseDF, newAttributes, removedAttributes] # return new dataframe, list of kept attributes and list of removed attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = makingNewDataset(correlation_matrix, portugeseDF); \n",
    "newDataset = temp[0]; \n",
    "keptAttributes = temp[1]; \n",
    "removedAttributes = temp[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTheModel (dataframe, modelName, modelToRun):\n",
    "    features = dataframe.drop(columns=[TARGET]); target = dataframe[TARGET]\n",
    "    featureTrain, featureTest, targetTrain, targetTest = train_test_split(features, target, test_size=TEST_SIZE, random_state=42)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    featureTrain = scaler.fit_transform(featureTrain)\n",
    "    featureTest = scaler.transform(featureTest)\n",
    "\n",
    "    modelToRun.fit(featureTrain, targetTrain)\n",
    "\n",
    "    testPredictions = modelToRun.predict(featureTest)\n",
    "    accuracy = accuracy_score(targetTest, testPredictions)\n",
    "    print(f\"{modelName} Accuracy: \\t{accuracy * 100:.3f}%\")\n",
    "\n",
    "    \n",
    "    # evaluate the model\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(targetTest, testPredictions))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(targetTest, testPredictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test Section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Kept Features:\t\t\t['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'G3']\n",
      "List Removed Features:\t\t\t[]\n",
      "Original / Removed / Kept:\t\t33 / 0 / 34\n",
      "\n",
      "Logistic Regression Model Accuracy: \t84.615%\n",
      "Confusion Matrix:\n",
      " [[109   2   1   0]\n",
      " [ 11   1   0   1]\n",
      " [  1   0   0   0]\n",
      " [  3   1   0   0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       112\n",
      "           1       0.25      0.08      0.12        13\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.85       130\n",
      "   macro avg       0.28      0.26      0.26       130\n",
      "weighted avg       0.78      0.85      0.81       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LogisticRegressionModel = LogisticRegression()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"List Kept Features:\\t\\t\\t{keptAttributes}\"); print(f\"List Removed Features:\\t\\t\\t{removedAttributes}\")\n",
    "print(f\"Original / Removed / Kept:\\t\\t{len(portugeseDF.keys())} / {len(removedAttributes)} / {len(keptAttributes)}\")\n",
    "\n",
    "runTheModel(newDataset, \"\\nLogistic Regression Model\", LogisticRegressionModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
