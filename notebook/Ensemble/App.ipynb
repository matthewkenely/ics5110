{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ICS5110 Notebook**\n",
    "\n",
    "View the web page for this project [here](https://mkenely.com/ics5110).\n",
    "\n",
    "- [Feature Reference](https://mkenely.com/ics5110/features)\n",
    "- [Feature Distributions](https://mkenely.com/ics5110/distributions)\n",
    "- [Correlation Matrix](https://mkenely.com/ics5110/correlation_matrix)\n",
    "- [Feature vs G3 Scatter Plots](https://mkenely.com/ics5110/scatter_plots)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle\n",
    "\n",
    "from gradio_implementations import pca_gradio\n",
    "from gradio_implementations import ensemble_gradio\n",
    "from gradio_implementations import kmc_gradio\n",
    "from gradio_implementations import lr_gradio\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugese_df = pd.read_csv('./data/Portuguese.csv')\n",
    "\n",
    "le = LabelEncoder()\n",
    "encoding_mappings = {}\n",
    "\n",
    "for column in portugese_df.columns:\n",
    "    if portugese_df[column].dtype == 'object':\n",
    "        portugese_df[column] = le.fit_transform(portugese_df[column])\n",
    "        encoding_mappings[column] = {index: label for index, label in enumerate(le.classes_)}\n",
    "\n",
    "X = portugese_df.drop('G3', axis=1)\n",
    "X = X.drop('G1', axis=1)\n",
    "X = X.drop('G2', axis=1)\n",
    "\n",
    "y = portugese_df['G3']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ensemble (David)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression # to use Logistic Regression for step of stacking \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier # to use RF and GB as base models + the stacked model\n",
    "from sklearn.metrics import accuracy_score # to get the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"G3\" # the target variable\n",
    "\n",
    "# ONE_BOUND is the bounding area from the extremes (ie. 1 and -1), to remove the models that are too correlated with the target\n",
    "# ZERO_BOUND is the bounding area from the middle (ie. 0), to remove the models that are too uncorrelated with the target\n",
    "ONE_BOUND = 0.8\n",
    "ZERO_BOUND = 0.065\n",
    "\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the two base models for the stacking model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100)\n",
    "gradient_boosting_model = GradientBoostingClassifier(n_estimators=100)\n",
    "\n",
    "# stacking model that uses a 5 fold cross validation scheme (cv)\n",
    "stacking_ensemble_model = StackingClassifier(estimators=[(\"random_forest\", random_forest_model), (\"gradient_boosting\", gradient_boosting_model)], final_estimator=LogisticRegression(), cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = portugese_df.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool), k=1)\n",
    "correlation_matrix = correlation_matrix.mask(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_features(correlation_matrix, dataframe):\n",
    "    original_features = dict(correlation_matrix.loc[TARGET])\n",
    "    new_features = []\n",
    "    removed_features = []\n",
    "\n",
    "    # Iterate through features to determine which to keep or remove\n",
    "    for key in original_features:\n",
    "        if key == TARGET:\n",
    "            new_features.append(key)  # Add target to the new dataframe\n",
    "        elif original_features[key] > ONE_BOUND or original_features[key] < -ONE_BOUND:\n",
    "            removed_features.append(key)  # High correlation\n",
    "        elif -ZERO_BOUND < original_features[key] < ZERO_BOUND:\n",
    "            removed_features.append(key)  # Low correlation\n",
    "        else:\n",
    "            new_features.append(key)  # Acceptable correlation range\n",
    "\n",
    "    # Create the new dataframe\n",
    "    new_data = {attribute: dataframe[attribute] for attribute in new_features}\n",
    "    new_dataframe = pd.DataFrame(new_data)\n",
    "\n",
    "    return new_dataframe, new_features, removed_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_the_model(dataframe, model_name, model_to_run):\n",
    "    # Split dataframe into features and target\n",
    "    features = dataframe.drop(columns=[TARGET])\n",
    "    target = dataframe[TARGET]\n",
    "\n",
    "    # Train-test split\n",
    "    feature_train, feature_test, target_train, target_test = train_test_split(\n",
    "        features, target, test_size=TEST_SIZE\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model_to_run.fit(feature_train, target_train)\n",
    "\n",
    "    # Make predictions and calculate accuracy\n",
    "    test_predictions = model_to_run.predict(feature_test)\n",
    "    accuracy = accuracy_score(target_test, test_predictions)\n",
    "    print(f\"{model_name} Accuracy:\\t{accuracy * 100:.3f}%\")\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(target_test, test_predictions, alpha=0.6, color='blue')\n",
    "\n",
    "    # Add a diagonal line for reference (perfect predictions)\n",
    "    min_val = min(min(target_test), min(test_predictions))\n",
    "    max_val = max(max(target_test), max(test_predictions))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title('Prediction vs Actual Values')\n",
    "    plt.xlabel('Actual G3')\n",
    "    plt.ylabel('Predicted G3')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests():\n",
    "    print(f\"Correlation values in range: {ONE_BOUND} to {ZERO_BOUND} and -{ZERO_BOUND} to -{ONE_BOUND}\\n\")\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "        temp = filter_features(correlation_matrix, portugese_df)\n",
    "        new_dataset, kept_features, removed_features = temp[0], temp[1], temp[2]\n",
    "\n",
    "        print(f\"List of Kept Features:\\t\\t\\t{kept_features}\")\n",
    "        print(f\"List of Removed Features:\\t\\t\\t{removed_features}\")\n",
    "        print(\n",
    "            f\"Original / Removed / Kept:\\t\\t\"\n",
    "            f\"{len(portugese_df.keys())} / {len(removed_features)} / {len(kept_features)}\"\n",
    "        )\n",
    "\n",
    "        run_the_model(new_dataset, \"\\nStacking Ensemble Model\", stacking_ensemble_model)\n",
    "\n",
    "        # # Save to pickle for gradio\n",
    "        # with open('../gradio/ensemble_gradio/models/kept_features.pkl', 'wb') as f:\n",
    "        #     pickle.dump(kept_features, f)\n",
    "\n",
    "        # with open('../gradio/ensemble_gradio/models/stacking_ensemble_model.pkl', 'wb') as f:\n",
    "        #     pickle.dump(stacking_ensemble_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == All Features ==\n",
    "# ONE_BOUND = 1 ; ZERO_BOUND = 0\n",
    "# run_tests()\n",
    "\n",
    "# == No High Correlation Features ==\n",
    "# ONE_BOUND = 0.8 ; ZERO_BOUND = 0 \n",
    "# run_tests()\n",
    "\n",
    "# == No Low Correlation Features ==\n",
    "# ONE_BOUND = 1 ; ZERO_BOUND = 0.065 \n",
    "# run_tests()\n",
    "\n",
    "# == No High and Low Correlation Features ==\n",
    "ONE_BOUND = 0.8 ; ZERO_BOUND = 0.065 \n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Gradio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ensemble**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "# Drop G3 from kept features\n",
    "kept_features.remove('G3')\n",
    "ensemble_gradio.make_gradio(kept_features, stacking_ensemble_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ics5110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
